[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Physics",
    "section": "",
    "text": "Preface\nI first learned to program in 2011 in Dr. Richard O. Gray’s computational physics course.\nIt was a revelatory experience that shaped my life. I enjoyed the class so much that I served as the TA the following year and later earned a PhD in Computational Science.\nI’ve kept the lecture notes on my various computers ever since. Rather than posting the original notes unchanged, I’m converting them into a Quarto book, possibly updating examples from C to Python and adding some of my own material.\nNote: Most of the content and examples are taken from Dr. Gray’s original course materials.\n\n\nColophon\nThis is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\nTo learn more about Quarto books, visit https://quarto.org/docs/books\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "04-interpolation.html",
    "href": "04-interpolation.html",
    "title": "1  Interpolation",
    "section": "",
    "text": "1.1 Linear Interpolation\nA common computational problem in physics involves determining the value of a particular function at one or more points of interest from a tabulation of that function. For instance, we may wish to calculate the index of refraction of a type of glass at a particular wavelength, but be faced with the problem that that particular wavelength is not explicitly in the tabulation. In such cases, we need to be able to interpolate in the table to find the value of the function at the point of interest. Let us take a particular example.\nBK-7 is a type of common optical crown glass. Its index of refraction \\(n\\) varies as a function of wavelength; for shorter wavelengths \\(n\\) is larger than for longer wavelengths, and thus violet light is refracted more strongly than red light, leading to the phenomenon of dispersion. The index of refraction is tabulated in Table 1.1.\nLet us suppose that we wish to find the index of refraction at a wavelength of \\(5000Å\\). Unfortunately, that wavelength is not found in the table, and so we must estimate it from the values in the table. We must make some assumption about how \\(n\\) varies between the tabular values. Presumably it varies in a smooth sort of way and does not take wild excursions between the tabulated values. The simplest and quite often an entirely adequate assumption to make is that the actual function varies linearly between the tabulated values. This is the basis of linear interpolation.\nHow do we carry out linear interpolation on the computer? Let us suppose that the function is tabulated at \\(N\\) points and takes on the values \\(y_1,y_2,y_3 ...\ny_N\\) at the points \\(x_1,x_2,x_3 ... x_N\\), and that we want to find the value of the function \\(y\\) at a point \\(x\\) that lies someplace in the interval between \\(x_1\\) and \\(x_N\\).\nThe first thing that we must do is to bracket \\(x\\), that is we must find a \\(j\\) such that \\(x_j &lt; x \\leq x_{j+1}\\). This can be accomplished by the following code fragment:\nwhere the xn’s are the tabulated points. When the if statement is satisfied, j is assigned the value of i and the procedure drops out of the loop. Please note that this is not the most efficient way to accomplish this task, especially if \\(N\\) is very large. We will look at a more efficient way later on.\nOnce we have bracketed \\(x\\), we can find the equation of the line between the points \\((x_j,y_j)\\) and \\((x_{j+1},y_{j+1})\\). This equation will be of the form \\(y = mx+b4 where\\)m$ is the slope and \\(b\\) is the y-intercept. As we all know, the slope is given by\n\\[\nm = \\frac{y_{j+1}-y_j}{x_{j+1}-x_j}\n\\]\nand the intercept can be found by substituting one point, say, \\((x_j,y_j)\\) into the resulting equation. Thus,\n\\[\nb=y-mx=y_j-\\frac{y_{j+1}-y_j}{x_{j+1}-x_j}x_j\n\\]\nyielding for the equation of the line, after some rearrangement,\n\\[\ny==y_j+\\left(\\frac{y_{j+1}-y_j}{x_{j+1}-x_j}\\right)(x-x_j)\n\\]\nIt is left to the student to show (for future reference) that this equation may be rewritten \\[\ny=Ay_j+By_{j+1}\n\\] where \\[\nA = \\frac{x_{j+1}-x}{x_{j+1}-x_j}\n\\] and \\[\nB = \\frac{x-x_j}{x_{j+1}-x_j}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Interpolation</span>"
    ]
  },
  {
    "objectID": "04-interpolation.html#linear-interpolation",
    "href": "04-interpolation.html#linear-interpolation",
    "title": "1  Interpolation",
    "section": "",
    "text": "Table 1.1: Refractive Index for BK7 Glass\n\n\n\n\n\n\n\n\\(\\lambda (Å)\\)\n\\(n\\)\n\n\n\n\n3511\n1.53894\n\n\n3638\n1.53648\n\n\n4047\n1.53024\n\n\n4358\n1.52669\n\n\n4416\n1.52611\n\n\n4579\n1.52462\n\n\n4658\n1.52395\n\n\n4727\n1.52339\n\n\n4765\n1.5231\n\n\n4800\n1.52283\n\n\n4861\n1.52238\n\n\n4880\n1.52224\n\n\n\n\n\n\n\n\n\\(\\lambda (Å)\\)\n\\(n\\)\n\n\n\n\n4965\n1.52165\n\n\n5017\n1.5213\n\n\n5145\n1.52049\n\n\n5320\n1.51947\n\n\n5461\n1.51872\n\n\n5876\n1.5168\n\n\n5893\n1.51673\n\n\n6328\n1.51509\n\n\n6438\n1.51472\n\n\n6563\n1.51432\n\n\n6943\n1.51322\n\n\n7860\n1.51106\n\n\n\n\n\n\n\n\n\\(\\lambda (Å)\\)\n\\(n\\)\n\n\n\n\n8210\n1.51037\n\n\n8300\n1.51021\n\n\n8521\n1.50981\n\n\n9040\n1.50894\n\n\n10140\n1.50731\n\n\n10600\n1.50669\n\n\n13000\n1.50371\n\n\n15000\n1.5013\n\n\n15500\n1.50068\n\n\n19701\n1.495\n\n\n23254\n1.48929\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteExercise 4.1\n\n\n\nDetermine, by hand, the value of the index of refraction of BK7 at \\(5000Å\\) using linear interpolation.\n\n\n\n\nfor(i=1;i&lt;N;i++) {\n  if(xn[i] &lt; x && xn[i+1] &gt;= x) {\n    j = i;\n    break; \n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteExercise 4.2\n\n\n\nWrite a C-function that will linearly interpolate the tabular data for the index of refraction of BK-7 and return a value for \\(n\\) for wavelengths between \\(3511Å\\) and \\(23254Å\\). Write a driver program that will use this function to prompt the user for a wavelength and then print to screen the corresponding value of \\(n\\).\n\n\n\n\n\n\n\n\nNoteExercise 4.3\n\n\n\nThe file data/boiling.dat contains data in two columns for the boiling point of water at different atmospheric pressures. The first column is the pressure in millibars, the second is the corresponding boiling point temperature in degrees Celsius. Write a C-function that initializes two vectors, P and T with the data in that data file (don’t read in the datafile – hardwire the data into your program), accepts the pressure as a double floating-point parameter, and returns the value of the temperature of the boiling point at that pressure. You should also write a driver program that will prompt the user for an atmospheric pressure, check whether it is within the limits of the data \\((50 ≤ P ≤ 2150)\\), calls your C-function, and prints to the screen the boiling point of water at that pressure.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Interpolation</span>"
    ]
  },
  {
    "objectID": "04-interpolation.html#polynomial-interpolation",
    "href": "04-interpolation.html#polynomial-interpolation",
    "title": "1  Interpolation",
    "section": "1.2 Polynomial Interpolation",
    "text": "1.2 Polynomial Interpolation\nLinear interpolation is good enough for government work, and it is even better than that. Because it is simple and makes the simplest possible assumption about the data, it should be employed in all cases except where it is manifestly inadequate. There are such cases. Sometimes the function being interpolated is very non-linear or has been tabulated at such wide intervals that linear interpolation would lead to large errors. Some applications demand more than simply the functional values at the interpolated points; sometimes the derivative of the function is required as well. With linear interpolation, the derivative is a constant between the tabulated points, and may actually be undefined at the tabulated points!\nFor such applications it may be best to interpolate using a polynomial interpolating function or functions. It can be shown that the following poly- nomial \\(P(x)\\) of degree \\(N−1\\) will exactly pass through the N tabulated points of the function \\(y = f(x)\\):\n\\[\n\\begin{aligned}\nP(x) =\\;&\n\\frac{(x - x_2)(x - x_3)\\cdots(x - x_N)}\n     {(x_1 - x_2)(x_1 - x_3)\\cdots(x_1 - x_N)}\\,y_1 \\\\[1em]\n&+ \\frac{(x - x_1)(x - x_3)\\cdots(x - x_N)}\n     {(x_2 - x_1)(x_2 - x_3)\\cdots(x_2 - x_N)}\\,y_2 \\\\[1em]\n&+ \\cdots \\\\[1em]\n&+ \\frac{(x - x_1)(x - x_2)\\cdots(x - x_{N-1})}\n     {(x_N - x_1)(x_N - x_2)\\cdots(x_N - x_{N-1})}\\,y_N\n\\end{aligned}\n\\]\nThe problem with the direct application of the polynomial \\(P(x)\\) is that for tabulations with many points, it can lead to very high degree polynomials. For instance, if a function is tabulated at 100 points, the above equation would yield a polynomial of degree 99! Such a polynomial could potentially fluctuate wildly between the tabulated points and thus not be a good representation of the actual function. \\(P(x)\\) is more usually applied to subsets of the tabulated points. For instance, if the polynomial is applied to subsets of 3 points, it yields parabolic interpolation, which can be much superior to linear interpolation if the function has a number of minima and maxima.\nOne problem with parabolic 3-point interpolation is that when it comes to bracketing \\(x\\), there is an ambiguity – does one bracket between \\(x_1\\) and \\(x_2\\) or between \\(x_2\\) and \\(x_3\\)? This is one reason why cubic 4-point interpolation is more commonly practiced – the bracketing is then between \\(x_2\\) and \\(x_3\\) with no ambiguity. Such interpolation is also called Lagrangian 4-point interpolation. The Lagrangian 4-point interpolation equation can be written:\n\\[\n\\begin{aligned}\nL(x) =\\;&\n\\frac{(x - x_2)(x - x_3)(x - x_4)}\n     {(x_1 - x_2)(x_1 - x_3)(x_1 - x_4)}\\,y_1 \\\\[1em]\n&+ \\frac{(x - x_1)(x - x_3)(x - x_4)}\n     {(x_2 - x_1)(x_2 - x_3)(x_2 - x_4)}\\,y_2 \\\\[1em]\n&+ \\frac{(x - x_1)(x - x_2)(x - x_4)}\n     {(x_3 - x_1)(x_3 - x_2)(x_3 - x_4)}\\,y_3 \\\\[1em]\n&+ \\frac{(x - x_1)(x - x_2)(x - x_3)}\n     {(x_4 - x_1)(x_4 - x_2)(x_4 - x_3)}\\,y_4\n\\end{aligned}\n\\]\nwhich the student can easily verify by reference to the equation for \\(P(x)\\).\nTo apply this interpolation equation, the user should first bracket \\(x\\) between \\(x_j\\) and \\(x_{j+1}\\) as before, but now identify \\(x_j\\) with \\(x_2\\) in the above equation and \\(x_{j+1}\\) with \\(x_3\\). It then follows that \\(x_1\\) will be \\(x_{j−1}\\) and \\(x_4\\) will be \\(x_{j+2}\\). The perceptive student will see that this will lead to a problem at the endpoints. For instance, if \\(x\\) is situated between the first two tabulated points, \\(x_{j−1}\\) will be undefined. Likewise, if \\(x\\) is situated between the last two tabulated points, \\(x_{j+2}\\) will be undefined. Thus in those intervals, the user must either interpolate linearly, or, in the first case, use the polynomial that would be used for an \\(x\\) bracketed between the 2nd and 3rd tabulated points, and similarly for the last case.\n\n\n\n\n\n\nNoteExercise 4.4\n\n\n\nWrite a C-function that will implement the 4-point Lagrangian interpolation formula above. For the endpoints, use the polynomial that would have been defined for the adjacent interval as described above. Modify the driver program in Exercise 4.2 (interpolation in a table of the wavelength and the index of refraction for BK-7 glass) to use this new C-function. Compare the results between the two programs.\n\n\n\n\n\n\n\n\nNoteExercise 4.5\n\n\n\nWrite a C-function that will implement the 4-point Lagrangian interpolation formula above. For the endpoints, use the polynomial that would have been defined for the adjacent interval as described above. Modify the driver program in Exercise 4.3 (interpolation in a table of atmospheric pressure and the boiling point of water) to use this new C-function. Compare the results between the two programs.\n\n\nWe have only scratched the surface of the subject of interpolation. The subject of Extrapolation – finding a value for a function outside the range of the defined points – is much more dangerous. Interpolation schemes can be used for extrapolation, but only with great care!\nBefore we leave the subject of interpolation, let us examine one further subject, that of efficiently bracketing \\(x\\). If we have a set of \\(x\\)’s (say in a vector x[i]) in numerical order that we must find interpolated values for, there is a simple time saving step that we can use, implemented in the following fragment of code (assume x is a vector of dimension n):\nj = 1;\nfor(k=1;k&lt;=n;k++) { \n  for(i=j;i&lt;N;i++) {\n    if(xn[i] &lt; x[k] && xn[i+1] &gt;= x[k]) { \n      j = i;\n      break; \n    }\n  }\n  here is your interpolation function code \n}\nNotice that the second for loop begins at i=j and not i=1; since the \\(x_k\\)’s are in numerical order, if \\(x_k\\) is bracketed between xn[j] and xn[j+1], there is no need to search beginning at i=1 for \\(x_{k+1}\\) because it will either be bracketed between the same pair or later pairs (note that we are obviously also assuming that the xn[j]’s are in numerical order). This can save an enormous amount of time in a code that needs to interpolate in a large (say \\(N &gt; 100\\)) table. Another useful trick is that of bisection. Further notes on bisection and other techniques for efficiently bracketing \\(x\\) can be found in Numerical Recipes (Press et al. 1992).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Interpolation</span>"
    ]
  },
  {
    "objectID": "04-interpolation.html#interpolation-in-2-dimensions",
    "href": "04-interpolation.html#interpolation-in-2-dimensions",
    "title": "1  Interpolation",
    "section": "1.3 Interpolation in 2 dimensions",
    "text": "1.3 Interpolation in 2 dimensions\nSome problems require interpolation in a two-dimensional grid of data. Let us suppose, for instance, that \\(y = y(x_1, x_2)\\) where \\(x_1\\) and \\(x_2\\) are the two independent variables. The functional value \\(y\\) is tabulated on a Cartesian grid, and so the first thing the programmer must do is to bracket the desired point \\((x_1, x_2)\\) in this grid (see figure below):\n\n\n\n\n\n\n\n\n\nThis bracketing can be done by bracketing in the two dimensions one at a time, using the technique discussed earlier.\nThe simplest interpolation technique in two dimensions is bilinear interpolation. If we define\n\\[\n\\begin{aligned}\ny_1 &= y(x_{1,i}, x_{2,j}) \\\\\ny_2 &= y(x_{1,i+1}, x_{2,j}) \\\\\ny_3 &= y(x_{1,i+1}, x_{2,j+1}) \\\\\ny_4 &= y(x_{1,i}, x_{2,j+1})\n\\end{aligned}\n\\]\ni.e., working our way counterclockwise around the above figure, then the interpolation formulae are:\n\\[\n\\begin{aligned}\nt &= (x_1 - x_{1,i})/(x_{1,i+1} - x_{1,i}) \\\\\nu &= (x_2 - x_{2,j})/(x_{2,j+1} - x_{2,j})\n\\end{aligned}\n\\]\nwhich make both \\(t\\) and \\(u\\) lie between 0 and 1. Then,\n\\[\ny(x_1, x_2) = (1 - t)(1 - u)y_1 + t(1 - u)y_2 + tu y_3 + (1 - t)u y_4\n\\]\nwhere \\((x_1, x_2)\\) are the coordinates of the desired point.\n\n\n\n\n\n\nNoteExercise 4.6\n\n\n\n A good example of the need to carry out interpolation in two dimensions is found in the calculation of partition functions. In certain plasma-physics contexts, it is necessary to calculate the partition functions of atoms and ions.\nA partition function, \\(U\\), is essentially an overall “statistical weight” for the atom, calculated by carrying out a weighted sum — weighted according to the populations of the levels — of the statistical weights for all of the energy levels in the atom.\nAt low temperatures, the partition function is simply the statistical weight of the ground level of the atom, but at higher temperatures, the partition function becomes larger, as the populations in the excited levels become significant.\nThe partition function is also a function of density, as at high densities in the plasma, the outermost energy levels are effectively “stripped off,” resulting in a lowering of the ionization energy, usually denoted as \\(\\Delta E\\). Thus, \\(U = U(T, \\Delta E)\\).\nBecause the calculation for a partition function can be very complex, they are usually calculated and tabulated so that users need not carry out the full calculation. The following table is a tabulation for the partition function for the hydrogen atom:\n\n\n\nTable 1.2: The Hydrogen Partition Function\n\n\n\n\n\nT (K)\nΔE = 0.10\nΔE = 0.50\nΔE = 1.00\nΔE = 2.00\n\n\n\n\n3250\n2.000\n2.000\n2.000\n2.000\n\n\n10083\n2.000\n2.000\n2.000\n2.000\n\n\n14188\n2.025\n2.006\n2.005\n2.004\n\n\n15643\n2.068\n2.016\n2.012\n2.009\n\n\n17246\n2.168\n2.037\n2.027\n2.020\n\n\n19014\n2.384\n2.080\n2.058\n2.040\n\n\n20963\n2.814\n2.162\n2.114\n2.078\n\n\n23111\n3.610\n2.308\n2.213\n2.142\n\n\n25480\n4.991\n2.551\n2.377\n2.246\n\n\n\n\n\n\nWrite a function that will perform a 2-D interpolation in this table, and use it to determine the partition function for Hydrogen at the following points \\((T,\\Delta E)\\): (16000, 0.25), (18500, 1.50), (19000, 0.15), (25023, 1.99).\n\n\n\n\n\n\n\n\nNoteExercise 4.7\n\n\n\nThe study of plasmas is an important field of physics, and is essential in the understanding of the interiors of stars and the functioning of fusion reactors.\nHydrogen becomes increasingly ionized (hydrogen loses its electron when ionized) with increasing temperature, but the density of electrons, \\(N_e\\), also plays an important role.\nThe following table gives the ratio of ionized hydrogen atoms to all forms of hydrogen (neutral + ionized) as a function of both \\(T\\) (in kelvins) and \\(N_e\\) (number of electrons per cubic centimeter).\nWrite a C-function and driver that will interpolate in this table. The driver should prompt the user for \\(T\\) (in kelvins) and \\(N_e\\). Note that the table is tabulated in terms of \\(\\log N_e\\).\n\n\n\nTable 1.3: Hydrogen Ionization: Ratio of Ionized to Total\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT(K)\n10.0\n11.0\n12.0\n13.0\n14.0\n15.0\n16.0\n17.0\n\n\n\n\n1000.0\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.000\n0.0000\n\n\n2000.0\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.000\n0.0000\n\n\n3000.0\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.000\n0.0000\n\n\n4000.0\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.0000\n0.000\n0.0000\n\n\n5000.0\n0.0017\n0.0002\n0.0000\n0.0000\n0.0000\n0.0000\n0.000\n0.0000\n\n\n6000.0\n0.2980\n0.0407\n0.0042\n0.0004\n0.0000\n0.0000\n0.000\n0.0000\n\n\n7000.0\n0.9582\n0.6961\n0.1864\n0.0224\n0.0023\n0.0002\n0.000\n0.0000\n\n\n8000.0\n0.9979\n0.9791\n0.8241\n0.3191\n0.0448\n0.0047\n0.000\n0.0000\n\n\n9000.0\n0.9998\n0.9980\n0.9804\n0.8335\n0.3335\n0.0477\n0.005\n0.0005\n\n\n10000.0\n1.0000\n0.9997\n0.9971\n0.9713\n0.7719\n0.2529\n0.032\n0.0034\n\n\n11000.0\n1.0000\n0.9999\n0.9994\n0.9939\n0.9425\n0.6211\n0.140\n0.0161\n\n\n12000.0\n1.0000\n1.0000\n0.9998\n0.9984\n0.9841\n0.8606\n0.381\n0.0581\n\n\n13000.0\n1.0000\n1.0000\n0.9999\n0.9995\n0.9948\n0.9503\n0.656\n0.1607\n\n\n14000.0\n1.0000\n1.0000\n1.0000\n0.9998\n0.9980\n0.9807\n0.835\n0.3373\n\n\n15000.0\n1.0000\n1.0000\n1.0000\n0.9999\n0.9992\n0.9917\n0.922\n0.5448",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Interpolation</span>"
    ]
  },
  {
    "objectID": "04-interpolation.html#interpolation-in-python",
    "href": "04-interpolation.html#interpolation-in-python",
    "title": "1  Interpolation",
    "section": "1.4 Interpolation in Python",
    "text": "1.4 Interpolation in Python\nLet’s say you have run an experiment and have some data.\n\n# Pretend you don't know the functional form of the data.\nnum_samples = 11\nx_data = np.linspace(0, 10, num=num_samples) + np.random.normal(scale=.2, size=num_samples)\ny_data = np.cos(-x_data**2 / 9.0)            + np.random.normal(scale=.2, size=num_samples)\n\nfig, ax = plt.subplots()\nax.plot(x_data, y_data, 'o', color='C1')\n\n\n\n\n\n\n\n\nNow you want to connect the dots … I mean interpolate your data.\nNumpy has a method (numpy.interp) for simple linear interpolation. The method takes in an array of new x’s where you want to calculate the new y’s. The original x and y points are also needed.\n\nx_interp = np.linspace(x_data.min(), x_data.max(), num=1001)\ny_interp = np.interp(x_interp, x_data, y_data)\n\nfix, ax = plt.subplots()\nax.plot(x_interp, y_interp)\nax.plot(x_data, y_data, 'o')\n\n\n\n\n\n\n\n\nIf you want a fancier smooth line SciPy has got you covered! The interpolate subpackage contains many methods to suit your needs. These methods follow a different pattern than the Numpy approach. When using the SciPy interpolate methods you provide the original data points and are returned a function you can call to interpolate new values.\nAs an example consider the CubicSpline method\n\nfrom scipy.interpolate import CubicSpline\n\nf = CubicSpline(x_data, y_data)\n\ny_interp = f(x_interp)\n\nfix, ax = plt.subplots()\nax.plot(x_interp, y_interp)\nax.plot(x_data, y_data, 'o')\n\n\n\n\n\n\n\n\nQuick and easy! There are other interpolation methods. For instance, maybe you are concerned with the line overshooting the data. An alternative is to use a so-called monotone cubic interpolant which attempts to preserve the local shape implied by the data. An example is the PchipInterpolator.\n\nfrom scipy.interpolate import PchipInterpolator\n\nf = PchipInterpolator(x_data, y_data)\n\ny_interp = f(x_interp)\n\nfix, ax = plt.subplots()\nax.plot(x_interp, y_interp)\nax.plot(x_data, y_data, 'o')\n\n\n\n\n\n\n\n\nThese cubic methods are typically fine for most application. There is also a generalized method for making interpolating splines of any degree but use with caution. You may introduce unexpected wiggles!\n\nfrom scipy.interpolate import make_interp_spline\n\nf = make_interp_spline(x_data, y_data, k=5)\n\ny_interp = f(x_interp)\n\nfix, ax = plt.subplots()\nax.plot(x_interp, y_interp)\nax.plot(x_data, y_data, 'o')\n\n\n\n\n\n\n\n\nThere are other methods for 2-D interpolation and smoothing as well. Have a look at the SciPy Interpolation User Guide for more details.\n\n\n\n\nPress, William H., Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. 1992. Numerical Recipes in c (2nd Ed.): The Art of Scientific Computing. USA: Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Interpolation</span>"
    ]
  },
  {
    "objectID": "05-roots.html",
    "href": "05-roots.html",
    "title": "2  Finding the Root of a Function",
    "section": "",
    "text": "2.1 The Method of Bracketing and Bisection\nThe need to determine the roots of a function – i.e. where that function crosses the x-axis – is a recurring problem in practical and computational physics. For example, the density of matter in the interior of a star may be approximately represented by a type of function called a polytropic function. The edge or surface of the star occurs where the appropriate polytropic function goes to zero. There are many other examples. All of you know how to find analytically the roots of a parabola. For more complex functions, it may not be possible or easy to find the roots analytically, and so it is necessary to use numerical methods. The numerical method that is used depends upon whether or not it is possible to determine the derivative of the function. The function, for instance, may be given to us as a “black box” – it may be in tabular form, or given to us as a “C” function, or it may be known only through a recursion equation. In such a case, the appropriate method would be to more and more closely bracket the root until we know it to the precision that we desire. Alternately, we may be able to differentiate the function. In that case, we can use the Newton-Raphson method (or similar methods) to zero in on the root.\nThe first thing that we need to know in root-finding is an approximate location of the root we are interested in. How can we determine this? The easiest way is to use a plotting program, such as gnuplot, EXCEL, etc., to plot the function. Another way is to calculate the function at a number of points. Then, unless the function is pathological in some way, we can say that a root exists in the interval \\((a, b)\\) if \\(f(a)\\) and \\(f(b)\\) have opposite signs. An exception to this is a function with a singularity in this interval. Suppose \\(c\\) is in the interval \\((a, b)\\), and the function is given by \\[\nf(x) = \\frac{1}{x - c}\n\\] Then, \\(f(x)\\) has a singularity at \\(c\\) and not a root. There are other pathological functions such as \\(\\sin(1/x)\\), which has infinitely many roots in the vicinity of \\(x = 0\\). So, the user must be aware of such problems, as such pathologies will give problems to even the most clever programs.\nLet us assume that our function is fairly free of pathologies and that we know that there is a root in the interval \\((a, b)\\) and that we want to find it more exactly.\nThe simplest way to proceed is using the method of bisection. This method is straightforward. If we know that a root is in \\((a, b)\\) because \\(f(a)\\) has a different sign from \\(f(b)\\), then evaluate the function \\(f\\) at the midpoint of the interval, \\((a + b)/2\\), and examine its sign. Replace whichever limit (e.g. \\(a\\) or \\(b\\)) that has the same sign. Repeat the process until the interval is so small that we know the location of the root to the desired accuracy.\nThe “desired” accuracy must be within limits. As we have discussed before in class and lab, since computers use a fixed number of binary digits to represent floating-point numbers, there is a limit to the accuracy with which computers can represent numbers. To be precise, the smallest floating-point number which, when added to the floating-point number \\(1.0\\), produces a floating-point number different from \\(1.0\\), is termed the machine accuracy, \\(\\epsilon_m\\). Using single precision, most machines have \\(\\epsilon_m \\approx 1 \\times 10^{-8}\\). Using double precision, \\(\\epsilon_m \\approx 1 \\times 10^{-16}\\). It is always a good idea to back off from these numbers, and thus setting \\(\\epsilon_m\\) to \\(10^{-6}\\) and \\(10^{-14}\\) respectively are practical limits. Sometimes even those limits are too optimistic. Let us suppose that our \\((n - 1)^{\\text{th}}\\) and \\(n^{\\text{th}}\\) evaluations of the midpoint are \\(x_{n-1}\\) and \\(x_n\\), and that the root was initially in the interval \\((a, b)\\). We would then be justified in stopping our search if \\(|x_n - x_{n-1}| &lt; \\epsilon_m |b - a|\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Finding the Root of a Function</span>"
    ]
  },
  {
    "objectID": "05-roots.html#the-method-of-bracketing-and-bisection",
    "href": "05-roots.html#the-method-of-bracketing-and-bisection",
    "title": "2  Finding the Root of a Function",
    "section": "",
    "text": "NoteExercise 5.1\n\n\n\nThe polynomial \\(f(x) = 5x^2 + 9x - 80\\) has a root in the interval \\((3, 4)\\). Find the root to a precision of \\(10^{-6}\\) using the bisection method. Verify your root analytically.\n\n\n\nPlotting Functions in gnuplot\nWhen finding roots, it is a good idea to plot the function to get an idea of the position of the roots. This can be done in gnuplot. To plot the function of Exercise 5.1, enter the following commands:\ngnuplot&gt; f(x) = 5*x**2 + 9*x - 80\ngnuplot&gt; plot f(x)\ngnuplot&gt; g(x) = 0\ngnuplot&gt; replot g(x)\nNote that exponentiation in gnuplot is accomplished with “**”. Notice in the plot that \\(f(x)\\) has a root at about -5 and another between 3 and 4.\n\n\n\n\n\n\nNoteExercise 5.2\n\n\n\nBessel functions \\(J_0(x)\\), \\(J_1(x)\\), etc. often turn up in mathematical physics, especially in the context of optics and diffraction. The file comphys.c has a canned version of the Bessel function \\(J_0(x)\\). The function declaration (contained in the file comphys.h) for this function is\nfloat bessj0(float x)\nModify your program from Exercise 5.1 to find the first two positive roots of \\(J_0(x)\\).\n\n\n\n\n\n\n\n\nNoteExercise 5.3\n\n\n\nThe viscosity of air (in micropascal seconds) is given to good accuracy by the following polynomial (valid between \\(T = 100\\,\\text{K}\\) and \\(600\\,\\text{K}\\)):\n\\[\n\\eta = 3.61111 \\times 10^{-8} T^3 - 6.95238 \\times 10^{-5} T^2 + 0.0805437\\,T - 0.3\n\\]\nUse this polynomial to find the temperature \\(T\\) at which \\(\\eta = 20.1\\,\\mu\\text{Pa}\\cdot\\text{s}\\).\n\n\n\n\n\n\n\n\nNoteExercise 5.4\n\n\n\nAn atomic state decays with two time constants \\(\\tau_1\\) and \\(\\tau_2\\) and can be described by the equation:\n\\[\nN = \\frac{N_0}{2} \\left( e^{-t/\\tau_1} + e^{-t/\\tau_2} \\right)\n\\]\nFind, by the method of bisection, the time at which \\(N = N_0 / 2\\), i.e., the half-life of the state. Let \\(\\tau_1 = 5.697\\) and \\(\\tau_2 = 9.446\\). The program should first display (with gnuplot) the function (use \\(N_0 = 100.0\\)) and then prompt the user for an initial bracket. Hints: gnuplot does not recognize the variable t, so use x instead. You may wish to add the command set xrange [0:15] just before the plot f(x) command to give the plot a nice scaling. Use exp(x) for \\(e^x\\) in gnuplot.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Finding the Root of a Function</span>"
    ]
  },
  {
    "objectID": "05-roots.html#the-newton-raphson-method",
    "href": "05-roots.html#the-newton-raphson-method",
    "title": "2  Finding the Root of a Function",
    "section": "2.2 The Newton-Raphson Method",
    "text": "2.2 The Newton-Raphson Method\nIf we can calculate the first derivative of our function, then we can use a speedier (although somewhat more dangerous) method called the Newton-Raphson method.\nLet us suppose that we have a function as illustrated below, which has a root at \\(x = x_r\\), and that we have a rough estimate for that root of \\(x = x_0\\). Let us evaluate the derivative of this function at \\(x_0\\), \\(f'(x_0)\\). This derivative will be the slope of the tangent line to the function at the point \\((x_0, f(x_0))\\), and you can see that where it crosses the \\(x\\)-axis, \\(x_1\\), is a much better estimate to the root of the function than \\(x_0\\).\nThe process can be repeated to give an even better estimate, and so on. The equation of the first tangent line is (the student should verify):\n\\[\ny = f'(x_0)(x - x_0) + f(x_0)\n\\]\nIf we set \\(y = 0\\) to find the root of this line, we get\n\\[\nx_1 = x_0 - \\frac{f(x_0)}{f'(x_0)}\n\\]\nFrom this, we can derive the Newton–Raphson formula for the \\(n^{\\text{th}}\\) estimate of the root: \\[\nx_n = x_{n-1} - \\frac{f(x_{n-1})}{f'(x_{n-1})}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteExercise 5.5\n\n\n\nWrite a program to find the root for the polynomial of Exercise 5.1 using the Newton–Raphson method. Begin with an estimate \\(x_0 = 4\\). See what happens if you use a different starting point. Explore both positive and negative values for the starting point.\n\n\n\n\n\n\n\n\nNoteExercise 5.6\n\n\n\nWrite a program to solve the problem of Exercise 5.3 using the Newton–Raphson method. Begin with an estimate of \\(200\\,\\text{K}\\).\n\n\n\n\n\n\n\n\nNoteExercise 5.7\n\n\n\nWrite a program to solve the problem of Exercise 5.4 using the Newton–Raphson method.\n\n\nAn obvious danger to the Newton-Raphson method is that if there is a minimum or a maximum between the root and your starting point, the method will either not converge to the desired root at all, but to another one, or wander out to ±∞ at an ever accelerating pace. In addition, if you happen by bad luck to choose your beginning point at a maximum or minimum point, your program will never converge, but will blow up! Hence, as always, you should have a pretty good idea of the nature of your function before you attempt to find and “polish” roots.\n\n\n\n\n\n\nNoteExercise 5.8\n\n\n\nUse the fact that\n\\[\n\\frac{dJ_0(x)}{dx} = -J_1(x)\n\\]\nto calculate the first two roots of \\(J_0(x)\\).\nThe code for \\(J_1(x)\\) is in the file comphys.c, and the function definition is\nfloat bessj1(float x);\nwhich is contained in comphys.h.\n\n\n\n\n\n\n\n\nNoteExercise 5.9 An Iterative Problem\n\n\n\nIn ballistics, it is common to solve the equations of motion of a particle shot at an angle, \\(\\theta\\), above a horizontal surface with an initial velocity \\(v_0\\). The effects of air resistance play an important role that is often neglected in introductory or intermediate coursework. If the force of air resistance can be modeled as:\n\\[\nF_x = -k m \\dot{x} \\tag{1}\n\\]\n\\[\nF_y = -k m \\dot{y} \\tag{2}\n\\]\nthen the \\(x(t)\\) and \\(y(t)\\) solutions are:\n\\[\nx(t) = \\frac{v_0 \\cos \\theta}{k} \\left( 1 - e^{-k t} \\right) \\tag{3}\n\\]\n\\[\ny(t) = - \\frac{gt}{k} + \\frac{k v_0 \\sin \\theta + g}{k^2} \\left( 1 - e^{-k t} \\right)  \\tag{4}\n\\]\nThe time of flight of the projectile (the time elapsed before the projectile lands) is given as:\n\\[\nT = \\frac{v_0 \\sin \\theta + g}{gk} \\left( 1 - e^{-k T} \\right) \\tag{5}\n\\]\nNotice that \\(T\\) appears on both sides of equation (5). This is known as a “transcendental equation” which can be solved numerically using iteration. Note that this equation collapses to the simple expression for \\(T\\) when resistance is neglected (\\(k = 0\\)):\n\\[\nT(k=0) = \\frac{2 v_0 \\sin \\theta}{g} \\tag{6}\n\\]\nThe range of motion (the distance traveled by the projectile before landing) is:\n\\[\nR = x(t = T) \\tag{7}\n\\]\nIn the exercises below, use \\(\\theta = 60^\\circ\\), \\(v_0 = 600 \\, \\text{m/s}\\), and \\(|g| = 9.8 \\, \\text{m/s}^2\\).\n\nSolve for \\(T\\) (equation 5) numerically using iteration. In the first iteration, use the non-resistive expression for \\(T\\) (equation 6). Iterate until the solution converges to within a user-defined tolerance (error) – e.g., \\(\\Delta T\\) over successive iterations is less than the tolerance. Use a value of \\(k = 0.005\\) for this part only.\nFind the value of \\(k\\) that allows the projectile to travel 1500 meters (\\(R = 1500\\,\\text{m}\\)).\n[GRAD STUDENTS ONLY] Plot \\(y\\) vs. \\(x\\) using gnuplot for \\(k\\) values of 0.0, 0.005, 0.01, 0.02, 0.04, and 0.08. Also, show analytically how to get equation (6) from equation (5) (Hint: Use perturbation methods – i.e., expand \\(1 - e^{-kT}\\) in a power series expansion, and keep only the first few terms).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Finding the Root of a Function</span>"
    ]
  },
  {
    "objectID": "05-roots.html#root-finding-in-python",
    "href": "05-roots.html#root-finding-in-python",
    "title": "2  Finding the Root of a Function",
    "section": "2.3 Root Finding in Python",
    "text": "2.3 Root Finding in Python\nIn SciPy all of the root finding methods are in the optimize subpackage.\nTo show off how it is done consider this suspiciously familiar function\n\nimport numpy as np\nfrom scipy.special import j0\nimport matplotlib.pyplot as plt\nplt.rcParams.update({\n  'figure.figsize': (7, 2),\n  'axes.spines.top': False, \n  'axes.spines.right': False\n  })\n\nx = np.linspace(0, 16, 400)\nfig, ax = plt.subplots()\nax.plot(x, j0(x))\n\n\n\n\n\n\n\n\nAll of the root finding algorithems for scalar functions can be accessed via a single method root_scalar.\nLet’s use a different method for each root! We need to supply a bracket for where to limit our search and a method name.\n\nfrom scipy.optimize import root_scalar\n\nmethod = ['bisect' ,'brentq' ,'brenth' ,'ridder' ,'toms748']\nbracket = [[2,4], [5,7], [8, 10], [11,13], [14, 16]]\nresults = []\n\nfor m, b in zip(method, bracket):\n    results.append(root_scalar(j0, bracket=b, method=m))\n\nfig, ax = plt.subplots()\nax.plot(x, j0(x))\n\nfor result in results:\n    ax.plot(result.root, 0, 'o')\n\n\n\n\n\n\n\n\nA call to root_scaler retuns a RootResults object which contains more information than only the root value.\n\nresults[0]\n\n      converged: True\n           flag: converged\n function_calls: 42\n     iterations: 40\n           root: 2.404825557694494\n         method: bisect\n\n\nFor a full overview of the supported methods see the root_scalar documentation.\nOptimization is a vast subject of which we will cover more in the next chapter.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Finding the Root of a Function</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nPress, William H., Saul A. Teukolsky, William T. Vetterling, and Brian\nP. Flannery. 1992. Numerical Recipes in c (2nd Ed.): The Art of\nScientific Computing. USA: Cambridge University Press.",
    "crumbs": [
      "References"
    ]
  }
]